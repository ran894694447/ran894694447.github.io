<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="google-site-verification" content="hwbyg1-cR4rRE7dSO1YTwstr2CM5d_XJBXrcuTfGzsU" />
  <meta name="keywords" content="Hao Luo,AE-Reorient" />

  <title>Hao Luo</title>
  
  <meta name="author" content="Hao Luo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/1c.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hao Luo</name>
              </p>
              <p>Hao Luo is a master's student majoring in mechanical engineering from the School of Modern Post (School of Automation), Beijing University of Posts and Telecommunications, advised by Prof.Haibin Yan. He received his BS degree in mechanical engineering from the School of Modern Post (School of Automation), Beijing University of Posts and Telecommunications, Beijing, in 2022.
                 His main research areas are computer vision and robotic manipulation.
              </p>
              <p style="text-align:center">
                <a href="haroll_luo@bupt.edu.cn">Email</a> &nbsp/&nbsp
                 <a href="https://github.com/HarollLuo">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/1c.jpg"><img style="width:50%;max-width:50%" alt="profile photo" src="images/1c.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
       

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/AE-Reorient.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>AE-Reorient: Active Exploration based Reorientation for Robotic Pick-and-Place</papertitle>
              <br>
              <strong>Hao Luo</strong>, Zhenyu Wu, Haibin Yan
              <br>
              <br>
              <em>preprint
              <br>
              <br>
              <a href="data/AE-Reorient.pdf">[PDF]</a>
              <br>
              <p> We propose a framework named AE-Reorient actively explores the scene, allowing the robot to autonomously learn scene interaction strategies through reinforcement learning to search for target objects in clutter.</p>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src='images/FairScene.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle>FairScene: Learning Unbiased Object Interactions for Indoor Scene Synthesis</papertitle>
                <br>
                Zhenyu Wu, Ziwei Wang, Shengyu Liu, <strong>Hao Luo</strong>, Jiwen Lu, and Haibin Yan
                <br>
                <br>
                <em>preprint
                <br>
                <br>
                <a href="data/FairScene.pdf">[PDF]</a>
                <br>
                <p> In this paper, we propose an unbiased graph neural network learning method called FairScene for indoor scene synthesis, which can fully exploit unbiased object interactions through causal reasoning, so that fair scene synthesis is achieved by calibrating the long-tailed category distribution and eliminating the confounder effects.</p>
              </td>
            </tr>
          
           




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> 2022 Outstanding graduate of Beijing</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> VCIP 2022
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
